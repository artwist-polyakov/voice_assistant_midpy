{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T16:26:27.441817Z",
     "start_time": "2024-05-29T16:24:37.551249Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install transformers torch",
   "id": "e9489f92bdc0ba27",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\r\n",
      "  Downloading transformers-4.41.1-py3-none-any.whl.metadata (43 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m43.8/43.8 kB\u001B[0m \u001B[31m427.3 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting torch\r\n",
      "  Downloading torch-2.3.0-cp310-none-macosx_11_0_arm64.whl.metadata (26 kB)\r\n",
      "Requirement already satisfied: filelock in /Users/master/Dropbox/Code cloud/Python/Middle Python/ProM1MidPy/DIPLOMA/graduate_work/.venv/lib/python3.10/site-packages (from transformers) (3.14.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /Users/master/Dropbox/Code cloud/Python/Middle Python/ProM1MidPy/DIPLOMA/graduate_work/.venv/lib/python3.10/site-packages (from transformers) (0.23.2)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/master/Dropbox/Code cloud/Python/Middle Python/ProM1MidPy/DIPLOMA/graduate_work/.venv/lib/python3.10/site-packages (from transformers) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/master/Dropbox/Code cloud/Python/Middle Python/ProM1MidPy/DIPLOMA/graduate_work/.venv/lib/python3.10/site-packages (from transformers) (23.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/master/Dropbox/Code cloud/Python/Middle Python/ProM1MidPy/DIPLOMA/graduate_work/.venv/lib/python3.10/site-packages (from transformers) (6.0.1)\r\n",
      "Collecting regex!=2019.12.17 (from transformers)\r\n",
      "  Downloading regex-2024.5.15-cp310-cp310-macosx_11_0_arm64.whl.metadata (40 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m40.9/40.9 kB\u001B[0m \u001B[31m2.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m-:--:--\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: requests in /Users/master/Dropbox/Code cloud/Python/Middle Python/ProM1MidPy/DIPLOMA/graduate_work/.venv/lib/python3.10/site-packages (from transformers) (2.31.0)\r\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/master/Dropbox/Code cloud/Python/Middle Python/ProM1MidPy/DIPLOMA/graduate_work/.venv/lib/python3.10/site-packages (from transformers) (0.19.1)\r\n",
      "Collecting safetensors>=0.4.1 (from transformers)\r\n",
      "  Downloading safetensors-0.4.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (3.8 kB)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/master/Dropbox/Code cloud/Python/Middle Python/ProM1MidPy/DIPLOMA/graduate_work/.venv/lib/python3.10/site-packages (from transformers) (4.66.4)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/master/Dropbox/Code cloud/Python/Middle Python/ProM1MidPy/DIPLOMA/graduate_work/.venv/lib/python3.10/site-packages (from torch) (4.11.0)\r\n",
      "Collecting sympy (from torch)\r\n",
      "  Downloading sympy-1.12-py3-none-any.whl.metadata (12 kB)\r\n",
      "Collecting networkx (from torch)\r\n",
      "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\r\n",
      "Requirement already satisfied: jinja2 in /Users/master/Dropbox/Code cloud/Python/Middle Python/ProM1MidPy/DIPLOMA/graduate_work/.venv/lib/python3.10/site-packages (from torch) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /Users/master/Dropbox/Code cloud/Python/Middle Python/ProM1MidPy/DIPLOMA/graduate_work/.venv/lib/python3.10/site-packages (from torch) (2024.5.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/master/Dropbox/Code cloud/Python/Middle Python/ProM1MidPy/DIPLOMA/graduate_work/.venv/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/master/Dropbox/Code cloud/Python/Middle Python/ProM1MidPy/DIPLOMA/graduate_work/.venv/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/master/Dropbox/Code cloud/Python/Middle Python/ProM1MidPy/DIPLOMA/graduate_work/.venv/lib/python3.10/site-packages (from requests->transformers) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/master/Dropbox/Code cloud/Python/Middle Python/ProM1MidPy/DIPLOMA/graduate_work/.venv/lib/python3.10/site-packages (from requests->transformers) (2.2.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/master/Dropbox/Code cloud/Python/Middle Python/ProM1MidPy/DIPLOMA/graduate_work/.venv/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\r\n",
      "Collecting mpmath>=0.19 (from sympy->torch)\r\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\r\n",
      "Downloading transformers-4.41.1-py3-none-any.whl (9.1 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m9.1/9.1 MB\u001B[0m \u001B[31m1.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading torch-2.3.0-cp310-none-macosx_11_0_arm64.whl (61.0 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m61.0/61.0 MB\u001B[0m \u001B[31m627.9 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:05\u001B[0m\r\n",
      "\u001B[?25hDownloading regex-2024.5.15-cp310-cp310-macosx_11_0_arm64.whl (278 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m278.3/278.3 kB\u001B[0m \u001B[31m800.9 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m \u001B[36m0:00:01\u001B[0mm\r\n",
      "\u001B[?25hDownloading safetensors-0.4.3-cp310-cp310-macosx_11_0_arm64.whl (410 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m410.9/410.9 kB\u001B[0m \u001B[31m3.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0mm\r\n",
      "\u001B[?25hDownloading networkx-3.3-py3-none-any.whl (1.7 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.7/1.7 MB\u001B[0m \u001B[31m415.5 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading sympy-1.12-py3-none-any.whl (5.7 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m5.7/5.7 MB\u001B[0m \u001B[31m1.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m0:00:05\u001B[0m\r\n",
      "\u001B[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m536.2/536.2 kB\u001B[0m \u001B[31m1.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0mm\r\n",
      "\u001B[?25hInstalling collected packages: mpmath, sympy, safetensors, regex, networkx, torch, transformers\r\n",
      "Successfully installed mpmath-1.3.0 networkx-3.3 regex-2024.5.15 safetensors-0.4.3 sympy-1.12 torch-2.3.0 transformers-4.41.1\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T16:28:08.150843Z",
     "start_time": "2024-05-29T16:27:16.840488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "inputs = tokenizer.encode(\"Пример запроса\", return_tensors='pt')\n",
    "outputs = model.generate(inputs)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ],
   "id": "272bc8069c3ebf32",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9980f4a728004cb1808d07b6dad8ee59"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e90bfca3b15a4654929d25952f9198ed"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "33244b8d74ee4c7dba77e36dfdbb0745"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f9300caec64949f5b945ffaefbb34542"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "76fbbaf0e3284f43a24e78799732698f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6dddcec945324792a9c246f7838df132"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "79bb08b72a8c4261b856f374d05b0664"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пример запросание �\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/master/Dropbox/Code cloud/Python/Middle Python/ProM1MidPy/DIPLOMA/graduate_work/.venv/lib/python3.10/site-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T16:31:22.480026Z",
     "start_time": "2024-05-29T16:31:19.153082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Загрузка модели и токенизатора\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# Добавление pad_token, если он отсутствует\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "request = \"\"\"\n",
    "Ты компьютер, который выдаёт в командную строку список актёров через запятую из запроса.\n",
    "Определи, содержится ли в данном запросе уточнение по имени актёра.\n",
    "Запрос: Работы в которых снималась моника белуччи\n",
    "Если ты сомневаешься, ответь: none.\n",
    "Если есть имена актёров, перечисли их через запятую, переводя на английский язык.\n",
    "Ответ должен содержать только имена актёров через запятую или none.\n",
    "Примеры:\n",
    "Запрос: \"фильмы с Николаем Кейджем и Натали Портман\"\n",
    "Ответ: \"Nikolas Cage, Natalie Portman\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Токенизация входного текста\n",
    "inputs = tokenizer.encode(request, return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "# Генерация текста с указанием attention_mask и pad_token_id\n",
    "outputs = model.generate(\n",
    "    inputs,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    max_new_tokens=50  # Установка максимального количества новых токенов\n",
    ")\n",
    "\n",
    "# Декодирование и вывод результата\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
   ],
   "id": "7132e08498efb2f3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ты компьютер, который выдаёт в командную строку список актёров через запятую из запроса.\n",
      "Определи, содержится ли в данном запросе уточнение по имени актёра.\n",
      "Запрос: Работы в которых снималась моника белуччи\n",
      "Если ты сомневаешься, ответь: none.\n",
      "Если есть имена актёров, перечисли их через запятую, переводя на английский язык.\n",
      "Ответ должен содержать только имена актёров через запятую или none.\n",
      "Примеры:\n",
      "Запрос: \"фильмы с Николаем Кейджем и Натали Портман\"\n",
      "Ответ: \"Nikolas Cage, Natalie Portman\"\n",
      "\n",
      "\n",
      "Ответ: \"Nikolas Cage, Natalie Portman\"\n",
      "\n",
      "Ответ: \"Nikolas Cage, Natalie Portman\"\n",
      "\n",
      "Ответ: \"Nikolas Cage, Natalie\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-29T16:30:04.919516Z",
     "start_time": "2024-05-29T16:30:04.906493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import DistilGPT2LMHeadModel, DistilGPT2Tokenizer\n",
    "\n",
    "# Загрузка модели и токенизатора\n",
    "model = DistilGPT2LMHeadModel.from_pretrained('distilgpt2')\n",
    "tokenizer = DistilGPT2Tokenizer.from_pretrained('distilgpt2')\n",
    "\n",
    "# Токенизация входного текста\n",
    "inputs = tokenizer.encode(\"Пример запроса\", return_tensors='pt')\n",
    "\n",
    "# Генерация текста с указанием attention_mask и pad_token_id\n",
    "outputs = model.generate(\n",
    "    inputs,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    max_new_tokens=50  # Установка максимального количества новых токенов\n",
    ")\n",
    "\n",
    "# Декодирование и вывод результата\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
   ],
   "id": "c463825954b2672",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'DistilGPT2LMHeadModel' from 'transformers' (/Users/master/Dropbox/Code cloud/Python/Middle Python/ProM1MidPy/DIPLOMA/graduate_work/.venv/lib/python3.10/site-packages/transformers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DistilGPT2LMHeadModel, DistilGPT2Tokenizer\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Загрузка модели и токенизатора\u001B[39;00m\n\u001B[1;32m      4\u001B[0m model \u001B[38;5;241m=\u001B[39m DistilGPT2LMHeadModel\u001B[38;5;241m.\u001B[39mfrom_pretrained(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdistilgpt2\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'DistilGPT2LMHeadModel' from 'transformers' (/Users/master/Dropbox/Code cloud/Python/Middle Python/ProM1MidPy/DIPLOMA/graduate_work/.venv/lib/python3.10/site-packages/transformers/__init__.py)"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b917ef848e06d3e9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
